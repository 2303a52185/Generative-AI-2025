{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOcvUCgtS89g+lhLlhhlWpf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303a52185/Generative-AI-2025/blob/main/2185_WEEK_(07)_(Assign_07).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hhis6iGWSfEo",
        "outputId": "889fa642-6abb-4ebd-a0d4-02da1e344b56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.3931 - loss: 0.7131 - val_accuracy: 0.4545 - val_loss: 0.7033\n",
            "Epoch 2/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4157 - loss: 0.7061 - val_accuracy: 0.4675 - val_loss: 0.6994\n",
            "Epoch 3/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4799 - loss: 0.7003 - val_accuracy: 0.5000 - val_loss: 0.6959\n",
            "Epoch 4/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4694 - loss: 0.7039 - val_accuracy: 0.5000 - val_loss: 0.6928\n",
            "Epoch 5/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4789 - loss: 0.6991 - val_accuracy: 0.5130 - val_loss: 0.6901\n",
            "Epoch 6/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4600 - loss: 0.7003 - val_accuracy: 0.5195 - val_loss: 0.6874\n",
            "Epoch 7/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4644 - loss: 0.6943 - val_accuracy: 0.5519 - val_loss: 0.6849\n",
            "Epoch 8/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4781 - loss: 0.6944 - val_accuracy: 0.5519 - val_loss: 0.6826\n",
            "Epoch 9/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5262 - loss: 0.6875 - val_accuracy: 0.5584 - val_loss: 0.6805\n",
            "Epoch 10/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5728 - loss: 0.6809 - val_accuracy: 0.5649 - val_loss: 0.6783\n",
            "Epoch 11/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6027 - loss: 0.6782 - val_accuracy: 0.5584 - val_loss: 0.6764\n",
            "Epoch 12/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5895 - loss: 0.6782 - val_accuracy: 0.5974 - val_loss: 0.6744\n",
            "Epoch 13/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5708 - loss: 0.6808 - val_accuracy: 0.6104 - val_loss: 0.6726\n",
            "Epoch 14/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5915 - loss: 0.6777 - val_accuracy: 0.6234 - val_loss: 0.6708\n",
            "Epoch 15/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6020 - loss: 0.6764 - val_accuracy: 0.6234 - val_loss: 0.6690\n",
            "Epoch 16/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6262 - loss: 0.6707 - val_accuracy: 0.6234 - val_loss: 0.6673\n",
            "Epoch 17/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6514 - loss: 0.6713 - val_accuracy: 0.6169 - val_loss: 0.6657\n",
            "Epoch 18/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6234 - loss: 0.6681 - val_accuracy: 0.6104 - val_loss: 0.6642\n",
            "Epoch 19/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6618 - loss: 0.6661 - val_accuracy: 0.6104 - val_loss: 0.6626\n",
            "Epoch 20/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6731 - loss: 0.6633 - val_accuracy: 0.6169 - val_loss: 0.6611\n",
            "Epoch 21/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6925 - loss: 0.6601 - val_accuracy: 0.6234 - val_loss: 0.6596\n",
            "Epoch 22/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6509 - loss: 0.6682 - val_accuracy: 0.6299 - val_loss: 0.6581\n",
            "Epoch 23/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6392 - loss: 0.6651 - val_accuracy: 0.6364 - val_loss: 0.6567\n",
            "Epoch 24/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6721 - loss: 0.6593 - val_accuracy: 0.6429 - val_loss: 0.6553\n",
            "Epoch 25/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6903 - loss: 0.6542 - val_accuracy: 0.6494 - val_loss: 0.6539\n",
            "Epoch 26/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6509 - loss: 0.6629 - val_accuracy: 0.6623 - val_loss: 0.6525\n",
            "Epoch 27/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6732 - loss: 0.6550 - val_accuracy: 0.6688 - val_loss: 0.6511\n",
            "Epoch 28/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6893 - loss: 0.6564 - val_accuracy: 0.6688 - val_loss: 0.6498\n",
            "Epoch 29/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6888 - loss: 0.6533 - val_accuracy: 0.6753 - val_loss: 0.6485\n",
            "Epoch 30/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6737 - loss: 0.6523 - val_accuracy: 0.6753 - val_loss: 0.6472\n",
            "Epoch 31/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6780 - loss: 0.6522 - val_accuracy: 0.6818 - val_loss: 0.6459\n",
            "Epoch 32/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6559 - loss: 0.6582 - val_accuracy: 0.6818 - val_loss: 0.6447\n",
            "Epoch 33/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6689 - loss: 0.6525 - val_accuracy: 0.6753 - val_loss: 0.6434\n",
            "Epoch 34/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6955 - loss: 0.6488 - val_accuracy: 0.6753 - val_loss: 0.6422\n",
            "Epoch 35/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7018 - loss: 0.6495 - val_accuracy: 0.6818 - val_loss: 0.6409\n",
            "Epoch 36/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7111 - loss: 0.6443 - val_accuracy: 0.6818 - val_loss: 0.6397\n",
            "Epoch 37/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7233 - loss: 0.6401 - val_accuracy: 0.6948 - val_loss: 0.6385\n",
            "Epoch 38/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7106 - loss: 0.6373 - val_accuracy: 0.6948 - val_loss: 0.6373\n",
            "Epoch 39/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6780 - loss: 0.6439 - val_accuracy: 0.6883 - val_loss: 0.6361\n",
            "Epoch 40/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7192 - loss: 0.6341 - val_accuracy: 0.6948 - val_loss: 0.6349\n",
            "Epoch 41/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7028 - loss: 0.6374 - val_accuracy: 0.6948 - val_loss: 0.6338\n",
            "Epoch 42/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7326 - loss: 0.6329 - val_accuracy: 0.6948 - val_loss: 0.6326\n",
            "Epoch 43/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7182 - loss: 0.6385 - val_accuracy: 0.7013 - val_loss: 0.6314\n",
            "Epoch 44/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7488 - loss: 0.6258 - val_accuracy: 0.7013 - val_loss: 0.6303\n",
            "Epoch 45/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6976 - loss: 0.6417 - val_accuracy: 0.7013 - val_loss: 0.6291\n",
            "Epoch 46/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7149 - loss: 0.6311 - val_accuracy: 0.7013 - val_loss: 0.6280\n",
            "Epoch 47/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7099 - loss: 0.6328 - val_accuracy: 0.7013 - val_loss: 0.6269\n",
            "Epoch 48/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7018 - loss: 0.6364 - val_accuracy: 0.7013 - val_loss: 0.6258\n",
            "Epoch 49/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7299 - loss: 0.6255 - val_accuracy: 0.7013 - val_loss: 0.6247\n",
            "Epoch 50/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7477 - loss: 0.6249 - val_accuracy: 0.7013 - val_loss: 0.6236\n",
            "Epoch 51/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7374 - loss: 0.6218 - val_accuracy: 0.7013 - val_loss: 0.6225\n",
            "Epoch 52/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7363 - loss: 0.6235 - val_accuracy: 0.7078 - val_loss: 0.6214\n",
            "Epoch 53/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7396 - loss: 0.6189 - val_accuracy: 0.7078 - val_loss: 0.6203\n",
            "Epoch 54/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6964 - loss: 0.6283 - val_accuracy: 0.7013 - val_loss: 0.6192\n",
            "Epoch 55/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7436 - loss: 0.6122 - val_accuracy: 0.7013 - val_loss: 0.6182\n",
            "Epoch 56/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7215 - loss: 0.6246 - val_accuracy: 0.7078 - val_loss: 0.6171\n",
            "Epoch 57/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7151 - loss: 0.6182 - val_accuracy: 0.7078 - val_loss: 0.6160\n",
            "Epoch 58/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7183 - loss: 0.6196 - val_accuracy: 0.7078 - val_loss: 0.6150\n",
            "Epoch 59/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7313 - loss: 0.6121 - val_accuracy: 0.7078 - val_loss: 0.6139\n",
            "Epoch 60/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6943 - loss: 0.6270 - val_accuracy: 0.7078 - val_loss: 0.6129\n",
            "Epoch 61/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7038 - loss: 0.6174 - val_accuracy: 0.7078 - val_loss: 0.6119\n",
            "Epoch 62/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7122 - loss: 0.6191 - val_accuracy: 0.7078 - val_loss: 0.6108\n",
            "Epoch 63/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7294 - loss: 0.6109 - val_accuracy: 0.7078 - val_loss: 0.6098\n",
            "Epoch 64/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7312 - loss: 0.6066 - val_accuracy: 0.7078 - val_loss: 0.6088\n",
            "Epoch 65/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7449 - loss: 0.6080 - val_accuracy: 0.7078 - val_loss: 0.6078\n",
            "Epoch 66/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7154 - loss: 0.6178 - val_accuracy: 0.7078 - val_loss: 0.6068\n",
            "Epoch 67/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7298 - loss: 0.6008 - val_accuracy: 0.7143 - val_loss: 0.6058\n",
            "Epoch 68/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6906 - loss: 0.6140 - val_accuracy: 0.7078 - val_loss: 0.6048\n",
            "Epoch 69/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7078 - loss: 0.6128 - val_accuracy: 0.7078 - val_loss: 0.6038\n",
            "Epoch 70/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7082 - loss: 0.6043 - val_accuracy: 0.7078 - val_loss: 0.6028\n",
            "Epoch 71/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7055 - loss: 0.6128 - val_accuracy: 0.7078 - val_loss: 0.6019\n",
            "Epoch 72/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6978 - loss: 0.6129 - val_accuracy: 0.7078 - val_loss: 0.6009\n",
            "Epoch 73/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7025 - loss: 0.6174 - val_accuracy: 0.7078 - val_loss: 0.6000\n",
            "Epoch 74/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7537 - loss: 0.5881 - val_accuracy: 0.7078 - val_loss: 0.5990\n",
            "Epoch 75/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7487 - loss: 0.5956 - val_accuracy: 0.7078 - val_loss: 0.5981\n",
            "Epoch 76/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7541 - loss: 0.5860 - val_accuracy: 0.7078 - val_loss: 0.5972\n",
            "Epoch 77/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7274 - loss: 0.5967 - val_accuracy: 0.7143 - val_loss: 0.5962\n",
            "Epoch 78/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7451 - loss: 0.5842 - val_accuracy: 0.7143 - val_loss: 0.5953\n",
            "Epoch 79/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7366 - loss: 0.5947 - val_accuracy: 0.7143 - val_loss: 0.5944\n",
            "Epoch 80/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7124 - loss: 0.6013 - val_accuracy: 0.7143 - val_loss: 0.5935\n",
            "Epoch 81/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7426 - loss: 0.5858 - val_accuracy: 0.7143 - val_loss: 0.5927\n",
            "Epoch 82/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7392 - loss: 0.5819 - val_accuracy: 0.7143 - val_loss: 0.5918\n",
            "Epoch 83/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7121 - loss: 0.5936 - val_accuracy: 0.7143 - val_loss: 0.5909\n",
            "Epoch 84/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7345 - loss: 0.5833 - val_accuracy: 0.7208 - val_loss: 0.5900\n",
            "Epoch 85/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7454 - loss: 0.5824 - val_accuracy: 0.7273 - val_loss: 0.5892\n",
            "Epoch 86/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7496 - loss: 0.5847 - val_accuracy: 0.7273 - val_loss: 0.5883\n",
            "Epoch 87/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7434 - loss: 0.5711 - val_accuracy: 0.7273 - val_loss: 0.5875\n",
            "Epoch 88/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7367 - loss: 0.5849 - val_accuracy: 0.7338 - val_loss: 0.5866\n",
            "Epoch 89/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6940 - loss: 0.6021 - val_accuracy: 0.7273 - val_loss: 0.5858\n",
            "Epoch 90/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7040 - loss: 0.6003 - val_accuracy: 0.7273 - val_loss: 0.5850\n",
            "Epoch 91/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7528 - loss: 0.5811 - val_accuracy: 0.7273 - val_loss: 0.5842\n",
            "Epoch 92/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7498 - loss: 0.5753 - val_accuracy: 0.7273 - val_loss: 0.5834\n",
            "Epoch 93/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7431 - loss: 0.5742 - val_accuracy: 0.7208 - val_loss: 0.5826\n",
            "Epoch 94/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7546 - loss: 0.5640 - val_accuracy: 0.7208 - val_loss: 0.5818\n",
            "Epoch 95/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7535 - loss: 0.5695 - val_accuracy: 0.7208 - val_loss: 0.5810\n",
            "Epoch 96/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7199 - loss: 0.5934 - val_accuracy: 0.7208 - val_loss: 0.5802\n",
            "Epoch 97/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7455 - loss: 0.5656 - val_accuracy: 0.7273 - val_loss: 0.5794\n",
            "Epoch 98/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7357 - loss: 0.5683 - val_accuracy: 0.7273 - val_loss: 0.5787\n",
            "Epoch 99/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7211 - loss: 0.5826 - val_accuracy: 0.7273 - val_loss: 0.5779\n",
            "Epoch 100/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7420 - loss: 0.5665 - val_accuracy: 0.7338 - val_loss: 0.5772\n",
            "Epoch 101/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7225 - loss: 0.5774 - val_accuracy: 0.7338 - val_loss: 0.5764\n",
            "Epoch 102/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7459 - loss: 0.5784 - val_accuracy: 0.7338 - val_loss: 0.5757\n",
            "Epoch 103/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7425 - loss: 0.5659 - val_accuracy: 0.7338 - val_loss: 0.5750\n",
            "Epoch 104/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7037 - loss: 0.6047 - val_accuracy: 0.7338 - val_loss: 0.5742\n",
            "Epoch 105/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7469 - loss: 0.5649 - val_accuracy: 0.7338 - val_loss: 0.5735\n",
            "Epoch 106/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7502 - loss: 0.5682 - val_accuracy: 0.7338 - val_loss: 0.5728\n",
            "Epoch 107/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7594 - loss: 0.5505 - val_accuracy: 0.7403 - val_loss: 0.5721\n",
            "Epoch 108/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7558 - loss: 0.5601 - val_accuracy: 0.7468 - val_loss: 0.5714\n",
            "Epoch 109/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7318 - loss: 0.5742 - val_accuracy: 0.7532 - val_loss: 0.5707\n",
            "Epoch 110/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7341 - loss: 0.5690 - val_accuracy: 0.7468 - val_loss: 0.5700\n",
            "Epoch 111/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7676 - loss: 0.5694 - val_accuracy: 0.7468 - val_loss: 0.5693\n",
            "Epoch 112/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7629 - loss: 0.5656 - val_accuracy: 0.7468 - val_loss: 0.5687\n",
            "Epoch 113/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7390 - loss: 0.5855 - val_accuracy: 0.7468 - val_loss: 0.5680\n",
            "Epoch 114/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7597 - loss: 0.5538 - val_accuracy: 0.7403 - val_loss: 0.5673\n",
            "Epoch 115/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7529 - loss: 0.5647 - val_accuracy: 0.7403 - val_loss: 0.5667\n",
            "Epoch 116/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7734 - loss: 0.5560 - val_accuracy: 0.7403 - val_loss: 0.5661\n",
            "Epoch 117/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7622 - loss: 0.5526 - val_accuracy: 0.7468 - val_loss: 0.5654\n",
            "Epoch 118/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7420 - loss: 0.5629 - val_accuracy: 0.7468 - val_loss: 0.5648\n",
            "Epoch 119/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7426 - loss: 0.5721 - val_accuracy: 0.7468 - val_loss: 0.5642\n",
            "Epoch 120/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7588 - loss: 0.5630 - val_accuracy: 0.7532 - val_loss: 0.5636\n",
            "Epoch 121/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7819 - loss: 0.5564 - val_accuracy: 0.7532 - val_loss: 0.5630\n",
            "Epoch 122/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7415 - loss: 0.5603 - val_accuracy: 0.7532 - val_loss: 0.5624\n",
            "Epoch 123/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7598 - loss: 0.5477 - val_accuracy: 0.7532 - val_loss: 0.5618\n",
            "Epoch 124/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7356 - loss: 0.5613 - val_accuracy: 0.7532 - val_loss: 0.5612\n",
            "Epoch 125/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7381 - loss: 0.5623 - val_accuracy: 0.7532 - val_loss: 0.5606\n",
            "Epoch 126/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7420 - loss: 0.5654 - val_accuracy: 0.7532 - val_loss: 0.5601\n",
            "Epoch 127/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7496 - loss: 0.5491 - val_accuracy: 0.7532 - val_loss: 0.5595\n",
            "Epoch 128/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7564 - loss: 0.5474 - val_accuracy: 0.7532 - val_loss: 0.5589\n",
            "Epoch 129/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7808 - loss: 0.5416 - val_accuracy: 0.7532 - val_loss: 0.5583\n",
            "Epoch 130/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7566 - loss: 0.5561 - val_accuracy: 0.7532 - val_loss: 0.5578\n",
            "Epoch 131/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7729 - loss: 0.5392 - val_accuracy: 0.7532 - val_loss: 0.5572\n",
            "Epoch 132/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7680 - loss: 0.5454 - val_accuracy: 0.7532 - val_loss: 0.5567\n",
            "Epoch 133/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7580 - loss: 0.5486 - val_accuracy: 0.7532 - val_loss: 0.5562\n",
            "Epoch 134/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7683 - loss: 0.5465 - val_accuracy: 0.7532 - val_loss: 0.5556\n",
            "Epoch 135/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7451 - loss: 0.5538 - val_accuracy: 0.7532 - val_loss: 0.5551\n",
            "Epoch 136/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7480 - loss: 0.5506 - val_accuracy: 0.7532 - val_loss: 0.5546\n",
            "Epoch 137/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7393 - loss: 0.5671 - val_accuracy: 0.7532 - val_loss: 0.5540\n",
            "Epoch 138/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7388 - loss: 0.5526 - val_accuracy: 0.7532 - val_loss: 0.5535\n",
            "Epoch 139/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7548 - loss: 0.5474 - val_accuracy: 0.7532 - val_loss: 0.5530\n",
            "Epoch 140/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7672 - loss: 0.5546 - val_accuracy: 0.7532 - val_loss: 0.5525\n",
            "Epoch 141/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7443 - loss: 0.5526 - val_accuracy: 0.7532 - val_loss: 0.5520\n",
            "Epoch 142/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7241 - loss: 0.5688 - val_accuracy: 0.7532 - val_loss: 0.5515\n",
            "Epoch 143/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7497 - loss: 0.5476 - val_accuracy: 0.7532 - val_loss: 0.5510\n",
            "Epoch 144/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7544 - loss: 0.5531 - val_accuracy: 0.7532 - val_loss: 0.5506\n",
            "Epoch 145/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7321 - loss: 0.5547 - val_accuracy: 0.7532 - val_loss: 0.5501\n",
            "Epoch 146/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7477 - loss: 0.5384 - val_accuracy: 0.7532 - val_loss: 0.5496\n",
            "Epoch 147/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7701 - loss: 0.5422 - val_accuracy: 0.7597 - val_loss: 0.5491\n",
            "Epoch 148/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7752 - loss: 0.5326 - val_accuracy: 0.7597 - val_loss: 0.5487\n",
            "Epoch 149/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7742 - loss: 0.5288 - val_accuracy: 0.7597 - val_loss: 0.5482\n",
            "Epoch 150/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7544 - loss: 0.5414 - val_accuracy: 0.7597 - val_loss: 0.5478\n",
            "Epoch 151/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7702 - loss: 0.5307 - val_accuracy: 0.7662 - val_loss: 0.5473\n",
            "Epoch 152/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7604 - loss: 0.5419 - val_accuracy: 0.7662 - val_loss: 0.5469\n",
            "Epoch 153/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7507 - loss: 0.5558 - val_accuracy: 0.7662 - val_loss: 0.5464\n",
            "Epoch 154/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7652 - loss: 0.5282 - val_accuracy: 0.7662 - val_loss: 0.5460\n",
            "Epoch 155/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7345 - loss: 0.5378 - val_accuracy: 0.7662 - val_loss: 0.5456\n",
            "Epoch 156/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7502 - loss: 0.5510 - val_accuracy: 0.7662 - val_loss: 0.5452\n",
            "Epoch 157/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7249 - loss: 0.5642 - val_accuracy: 0.7662 - val_loss: 0.5448\n",
            "Epoch 158/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7570 - loss: 0.5506 - val_accuracy: 0.7662 - val_loss: 0.5443\n",
            "Epoch 159/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7580 - loss: 0.5371 - val_accuracy: 0.7597 - val_loss: 0.5439\n",
            "Epoch 160/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7252 - loss: 0.5505 - val_accuracy: 0.7597 - val_loss: 0.5435\n",
            "Epoch 161/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7415 - loss: 0.5331 - val_accuracy: 0.7597 - val_loss: 0.5431\n",
            "Epoch 162/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7882 - loss: 0.5291 - val_accuracy: 0.7597 - val_loss: 0.5427\n",
            "Epoch 163/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7477 - loss: 0.5316 - val_accuracy: 0.7597 - val_loss: 0.5423\n",
            "Epoch 164/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7608 - loss: 0.5201 - val_accuracy: 0.7597 - val_loss: 0.5419\n",
            "Epoch 165/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7550 - loss: 0.5272 - val_accuracy: 0.7597 - val_loss: 0.5415\n",
            "Epoch 166/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7655 - loss: 0.5389 - val_accuracy: 0.7532 - val_loss: 0.5412\n",
            "Epoch 167/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7426 - loss: 0.5547 - val_accuracy: 0.7532 - val_loss: 0.5408\n",
            "Epoch 168/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7455 - loss: 0.5361 - val_accuracy: 0.7532 - val_loss: 0.5404\n",
            "Epoch 169/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7413 - loss: 0.5530 - val_accuracy: 0.7532 - val_loss: 0.5400\n",
            "Epoch 170/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7639 - loss: 0.5246 - val_accuracy: 0.7532 - val_loss: 0.5397\n",
            "Epoch 171/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7491 - loss: 0.5254 - val_accuracy: 0.7532 - val_loss: 0.5393\n",
            "Epoch 172/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7817 - loss: 0.5285 - val_accuracy: 0.7532 - val_loss: 0.5390\n",
            "Epoch 173/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7492 - loss: 0.5417 - val_accuracy: 0.7532 - val_loss: 0.5387\n",
            "Epoch 174/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7964 - loss: 0.5080 - val_accuracy: 0.7532 - val_loss: 0.5383\n",
            "Epoch 175/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7555 - loss: 0.5216 - val_accuracy: 0.7532 - val_loss: 0.5380\n",
            "Epoch 176/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7662 - loss: 0.5436 - val_accuracy: 0.7532 - val_loss: 0.5376\n",
            "Epoch 177/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7825 - loss: 0.5018 - val_accuracy: 0.7532 - val_loss: 0.5373\n",
            "Epoch 178/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7360 - loss: 0.5420 - val_accuracy: 0.7532 - val_loss: 0.5370\n",
            "Epoch 179/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7720 - loss: 0.5230 - val_accuracy: 0.7532 - val_loss: 0.5367\n",
            "Epoch 180/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8186 - loss: 0.5015 - val_accuracy: 0.7597 - val_loss: 0.5363\n",
            "Epoch 181/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7644 - loss: 0.5196 - val_accuracy: 0.7597 - val_loss: 0.5360\n",
            "Epoch 182/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7526 - loss: 0.5391 - val_accuracy: 0.7597 - val_loss: 0.5357\n",
            "Epoch 183/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7644 - loss: 0.5365 - val_accuracy: 0.7597 - val_loss: 0.5354\n",
            "Epoch 184/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7793 - loss: 0.5215 - val_accuracy: 0.7597 - val_loss: 0.5351\n",
            "Epoch 185/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8052 - loss: 0.4972 - val_accuracy: 0.7597 - val_loss: 0.5348\n",
            "Epoch 186/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7862 - loss: 0.5054 - val_accuracy: 0.7532 - val_loss: 0.5345\n",
            "Epoch 187/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7637 - loss: 0.5293 - val_accuracy: 0.7597 - val_loss: 0.5342\n",
            "Epoch 188/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7615 - loss: 0.5179 - val_accuracy: 0.7597 - val_loss: 0.5339\n",
            "Epoch 189/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7739 - loss: 0.5125 - val_accuracy: 0.7597 - val_loss: 0.5336\n",
            "Epoch 190/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7720 - loss: 0.5162 - val_accuracy: 0.7532 - val_loss: 0.5333\n",
            "Epoch 191/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7635 - loss: 0.5210 - val_accuracy: 0.7532 - val_loss: 0.5330\n",
            "Epoch 192/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8008 - loss: 0.5093 - val_accuracy: 0.7532 - val_loss: 0.5327\n",
            "Epoch 193/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7724 - loss: 0.5112 - val_accuracy: 0.7532 - val_loss: 0.5325\n",
            "Epoch 194/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7804 - loss: 0.5113 - val_accuracy: 0.7532 - val_loss: 0.5322\n",
            "Epoch 195/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8101 - loss: 0.4872 - val_accuracy: 0.7532 - val_loss: 0.5319\n",
            "Epoch 196/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7772 - loss: 0.5261 - val_accuracy: 0.7532 - val_loss: 0.5316\n",
            "Epoch 197/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7879 - loss: 0.5073 - val_accuracy: 0.7532 - val_loss: 0.5314\n",
            "Epoch 198/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7838 - loss: 0.5189 - val_accuracy: 0.7532 - val_loss: 0.5311\n",
            "Epoch 199/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7907 - loss: 0.5089 - val_accuracy: 0.7532 - val_loss: 0.5308\n",
            "Epoch 200/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7575 - loss: 0.5375 - val_accuracy: 0.7468 - val_loss: 0.5306\n",
            "Epoch 201/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7565 - loss: 0.5087 - val_accuracy: 0.7468 - val_loss: 0.5303\n",
            "Epoch 202/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7951 - loss: 0.5109 - val_accuracy: 0.7468 - val_loss: 0.5301\n",
            "Epoch 203/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7770 - loss: 0.4987 - val_accuracy: 0.7532 - val_loss: 0.5298\n",
            "Epoch 204/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7801 - loss: 0.5045 - val_accuracy: 0.7532 - val_loss: 0.5296\n",
            "Epoch 205/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7744 - loss: 0.5096 - val_accuracy: 0.7532 - val_loss: 0.5293\n",
            "Epoch 206/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7854 - loss: 0.4929 - val_accuracy: 0.7532 - val_loss: 0.5291\n",
            "Epoch 207/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7797 - loss: 0.5166 - val_accuracy: 0.7532 - val_loss: 0.5289\n",
            "Epoch 208/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7830 - loss: 0.5115 - val_accuracy: 0.7532 - val_loss: 0.5286\n",
            "Epoch 209/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7690 - loss: 0.5283 - val_accuracy: 0.7597 - val_loss: 0.5284\n",
            "Epoch 210/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7792 - loss: 0.5184 - val_accuracy: 0.7597 - val_loss: 0.5282\n",
            "Epoch 211/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7665 - loss: 0.5209 - val_accuracy: 0.7597 - val_loss: 0.5279\n",
            "Epoch 212/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7806 - loss: 0.5057 - val_accuracy: 0.7597 - val_loss: 0.5277\n",
            "Epoch 213/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7478 - loss: 0.5178 - val_accuracy: 0.7597 - val_loss: 0.5275\n",
            "Epoch 214/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7974 - loss: 0.4907 - val_accuracy: 0.7597 - val_loss: 0.5273\n",
            "Epoch 215/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7800 - loss: 0.4939 - val_accuracy: 0.7597 - val_loss: 0.5270\n",
            "Epoch 216/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7875 - loss: 0.5008 - val_accuracy: 0.7597 - val_loss: 0.5268\n",
            "Epoch 217/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7768 - loss: 0.5017 - val_accuracy: 0.7597 - val_loss: 0.5266\n",
            "Epoch 218/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7990 - loss: 0.4971 - val_accuracy: 0.7597 - val_loss: 0.5264\n",
            "Epoch 219/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7735 - loss: 0.5244 - val_accuracy: 0.7597 - val_loss: 0.5261\n",
            "Epoch 220/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7836 - loss: 0.4881 - val_accuracy: 0.7597 - val_loss: 0.5259\n",
            "Epoch 221/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7839 - loss: 0.4872 - val_accuracy: 0.7597 - val_loss: 0.5257\n",
            "Epoch 222/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7660 - loss: 0.5361 - val_accuracy: 0.7597 - val_loss: 0.5255\n",
            "Epoch 223/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7929 - loss: 0.4963 - val_accuracy: 0.7597 - val_loss: 0.5253\n",
            "Epoch 224/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7832 - loss: 0.4934 - val_accuracy: 0.7597 - val_loss: 0.5251\n",
            "Epoch 225/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7789 - loss: 0.5227 - val_accuracy: 0.7662 - val_loss: 0.5249\n",
            "Epoch 226/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7667 - loss: 0.5001 - val_accuracy: 0.7662 - val_loss: 0.5247\n",
            "Epoch 227/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7867 - loss: 0.5048 - val_accuracy: 0.7662 - val_loss: 0.5245\n",
            "Epoch 228/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7826 - loss: 0.5098 - val_accuracy: 0.7662 - val_loss: 0.5243\n",
            "Epoch 229/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7796 - loss: 0.4900 - val_accuracy: 0.7662 - val_loss: 0.5242\n",
            "Epoch 230/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7747 - loss: 0.5084 - val_accuracy: 0.7662 - val_loss: 0.5240\n",
            "Epoch 231/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7417 - loss: 0.5222 - val_accuracy: 0.7662 - val_loss: 0.5238\n",
            "Epoch 232/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7659 - loss: 0.5065 - val_accuracy: 0.7662 - val_loss: 0.5236\n",
            "Epoch 233/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7879 - loss: 0.4957 - val_accuracy: 0.7662 - val_loss: 0.5234\n",
            "Epoch 234/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7610 - loss: 0.5018 - val_accuracy: 0.7662 - val_loss: 0.5233\n",
            "Epoch 235/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7787 - loss: 0.5112 - val_accuracy: 0.7662 - val_loss: 0.5231\n",
            "Epoch 236/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7521 - loss: 0.5105 - val_accuracy: 0.7662 - val_loss: 0.5229\n",
            "Epoch 237/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7699 - loss: 0.4881 - val_accuracy: 0.7597 - val_loss: 0.5227\n",
            "Epoch 238/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7436 - loss: 0.5070 - val_accuracy: 0.7597 - val_loss: 0.5226\n",
            "Epoch 239/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7821 - loss: 0.4898 - val_accuracy: 0.7597 - val_loss: 0.5224\n",
            "Epoch 240/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7433 - loss: 0.5370 - val_accuracy: 0.7597 - val_loss: 0.5223\n",
            "Epoch 241/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7740 - loss: 0.4814 - val_accuracy: 0.7597 - val_loss: 0.5221\n",
            "Epoch 242/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7831 - loss: 0.4980 - val_accuracy: 0.7597 - val_loss: 0.5219\n",
            "Epoch 243/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7514 - loss: 0.5131 - val_accuracy: 0.7597 - val_loss: 0.5218\n",
            "Epoch 244/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7564 - loss: 0.4981 - val_accuracy: 0.7597 - val_loss: 0.5216\n",
            "Epoch 245/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7622 - loss: 0.5022 - val_accuracy: 0.7597 - val_loss: 0.5214\n",
            "Epoch 246/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7951 - loss: 0.4767 - val_accuracy: 0.7597 - val_loss: 0.5213\n",
            "Epoch 247/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7823 - loss: 0.4876 - val_accuracy: 0.7597 - val_loss: 0.5211\n",
            "Epoch 248/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8082 - loss: 0.4717 - val_accuracy: 0.7597 - val_loss: 0.5210\n",
            "Epoch 249/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7852 - loss: 0.5015 - val_accuracy: 0.7597 - val_loss: 0.5208\n",
            "Epoch 250/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7875 - loss: 0.4921 - val_accuracy: 0.7597 - val_loss: 0.5207\n",
            "Epoch 251/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7779 - loss: 0.4962 - val_accuracy: 0.7597 - val_loss: 0.5206\n",
            "Epoch 252/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7765 - loss: 0.4928 - val_accuracy: 0.7597 - val_loss: 0.5204\n",
            "Epoch 253/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7544 - loss: 0.4903 - val_accuracy: 0.7597 - val_loss: 0.5203\n",
            "Epoch 254/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8062 - loss: 0.4741 - val_accuracy: 0.7597 - val_loss: 0.5201\n",
            "Epoch 255/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7601 - loss: 0.4951 - val_accuracy: 0.7597 - val_loss: 0.5200\n",
            "Epoch 256/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7584 - loss: 0.5096 - val_accuracy: 0.7597 - val_loss: 0.5198\n",
            "Epoch 257/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7587 - loss: 0.4945 - val_accuracy: 0.7597 - val_loss: 0.5197\n",
            "Epoch 258/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7686 - loss: 0.4849 - val_accuracy: 0.7597 - val_loss: 0.5196\n",
            "Epoch 259/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7975 - loss: 0.4858 - val_accuracy: 0.7597 - val_loss: 0.5195\n",
            "Epoch 260/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7988 - loss: 0.4719 - val_accuracy: 0.7597 - val_loss: 0.5193\n",
            "Epoch 261/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7635 - loss: 0.5006 - val_accuracy: 0.7597 - val_loss: 0.5192\n",
            "Epoch 262/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7570 - loss: 0.4822 - val_accuracy: 0.7597 - val_loss: 0.5191\n",
            "Epoch 263/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7814 - loss: 0.4678 - val_accuracy: 0.7597 - val_loss: 0.5190\n",
            "Epoch 264/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7767 - loss: 0.4755 - val_accuracy: 0.7532 - val_loss: 0.5188\n",
            "Epoch 265/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7898 - loss: 0.4944 - val_accuracy: 0.7532 - val_loss: 0.5187\n",
            "Epoch 266/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7440 - loss: 0.5183 - val_accuracy: 0.7532 - val_loss: 0.5186\n",
            "Epoch 267/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7718 - loss: 0.4944 - val_accuracy: 0.7532 - val_loss: 0.5185\n",
            "Epoch 268/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7663 - loss: 0.4882 - val_accuracy: 0.7532 - val_loss: 0.5184\n",
            "Epoch 269/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7993 - loss: 0.4634 - val_accuracy: 0.7532 - val_loss: 0.5183\n",
            "Epoch 270/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7905 - loss: 0.4823 - val_accuracy: 0.7468 - val_loss: 0.5182\n",
            "Epoch 271/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7704 - loss: 0.4964 - val_accuracy: 0.7468 - val_loss: 0.5181\n",
            "Epoch 272/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7447 - loss: 0.5083 - val_accuracy: 0.7468 - val_loss: 0.5180\n",
            "Epoch 273/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7899 - loss: 0.4810 - val_accuracy: 0.7468 - val_loss: 0.5179\n",
            "Epoch 274/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7884 - loss: 0.4628 - val_accuracy: 0.7468 - val_loss: 0.5177\n",
            "Epoch 275/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7609 - loss: 0.4998 - val_accuracy: 0.7468 - val_loss: 0.5176\n",
            "Epoch 276/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7789 - loss: 0.4860 - val_accuracy: 0.7468 - val_loss: 0.5175\n",
            "Epoch 277/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7558 - loss: 0.4994 - val_accuracy: 0.7468 - val_loss: 0.5175\n",
            "Epoch 278/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7625 - loss: 0.5199 - val_accuracy: 0.7468 - val_loss: 0.5173\n",
            "Epoch 279/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7788 - loss: 0.4821 - val_accuracy: 0.7468 - val_loss: 0.5172\n",
            "Epoch 280/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7716 - loss: 0.4782 - val_accuracy: 0.7468 - val_loss: 0.5172\n",
            "Epoch 281/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7765 - loss: 0.4942 - val_accuracy: 0.7468 - val_loss: 0.5171\n",
            "Epoch 282/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7576 - loss: 0.4986 - val_accuracy: 0.7468 - val_loss: 0.5170\n",
            "Epoch 283/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7665 - loss: 0.4995 - val_accuracy: 0.7468 - val_loss: 0.5169\n",
            "Epoch 284/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7544 - loss: 0.4938 - val_accuracy: 0.7468 - val_loss: 0.5168\n",
            "Epoch 285/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7616 - loss: 0.4941 - val_accuracy: 0.7468 - val_loss: 0.5167\n",
            "Epoch 286/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7735 - loss: 0.4947 - val_accuracy: 0.7468 - val_loss: 0.5165\n",
            "Epoch 287/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7358 - loss: 0.5140 - val_accuracy: 0.7468 - val_loss: 0.5164\n",
            "Epoch 288/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7300 - loss: 0.5215 - val_accuracy: 0.7468 - val_loss: 0.5164\n",
            "Epoch 289/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7497 - loss: 0.5110 - val_accuracy: 0.7468 - val_loss: 0.5163\n",
            "Epoch 290/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7542 - loss: 0.4977 - val_accuracy: 0.7468 - val_loss: 0.5162\n",
            "Epoch 291/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7466 - loss: 0.4959 - val_accuracy: 0.7532 - val_loss: 0.5161\n",
            "Epoch 292/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7793 - loss: 0.4571 - val_accuracy: 0.7532 - val_loss: 0.5160\n",
            "Epoch 293/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7820 - loss: 0.4870 - val_accuracy: 0.7532 - val_loss: 0.5159\n",
            "Epoch 294/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7707 - loss: 0.4958 - val_accuracy: 0.7532 - val_loss: 0.5159\n",
            "Epoch 295/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7788 - loss: 0.4868 - val_accuracy: 0.7532 - val_loss: 0.5158\n",
            "Epoch 296/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7679 - loss: 0.4833 - val_accuracy: 0.7532 - val_loss: 0.5157\n",
            "Epoch 297/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7836 - loss: 0.4716 - val_accuracy: 0.7532 - val_loss: 0.5156\n",
            "Epoch 298/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7863 - loss: 0.4640 - val_accuracy: 0.7532 - val_loss: 0.5156\n",
            "Epoch 299/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7736 - loss: 0.4619 - val_accuracy: 0.7532 - val_loss: 0.5155\n",
            "Epoch 300/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7988 - loss: 0.4582 - val_accuracy: 0.7532 - val_loss: 0.5154\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7112 - loss: 0.5270 \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Test Accuracy: 0.7532\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "Non-Diabetic       0.80      0.83      0.81        99\n",
            "    Diabetic       0.67      0.62      0.64        55\n",
            "\n",
            "    accuracy                           0.75       154\n",
            "   macro avg       0.73      0.72      0.73       154\n",
            "weighted avg       0.75      0.75      0.75       154\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unable to synchronously create dataset (name already exists)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-747d1de195ca>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m# Save the trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/diabetes_ann_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model saved successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36mcreate_dataset\u001b[0;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[1;32m    184\u001b[0m                     \u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mdsid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_new_dset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mdset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36mmake_new_dset\u001b[0;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, dapl, efile_prefix, virtual_prefix, allow_unknown_filter, rdcc_nslots, rdcc_nbytes, rdcc_w0, fill_time)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0msid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m     \u001b[0mdset_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5d.pyx\u001b[0m in \u001b[0;36mh5py.h5d.create\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unable to synchronously create dataset (name already exists)"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adagrad\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv(\"/content/Copy of diabetes(1).csv\")  # Change to your dataset\n",
        "\n",
        "# Split into features (X) and target (y)\n",
        "X = data.iloc[:, :-1].values  # All columns except the last\n",
        "y = data.iloc[:, -1].values   # Last column (target)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Save the scaler for future use\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "\n",
        "# Define the ANN model\n",
        "model = Sequential([\n",
        "    Dense(12, activation=\"swish\", input_shape=(X_train.shape[1],)),\n",
        "    Dense(25, activation=\"swish\"),\n",
        "    Dense(15, activation=\"swish\"),\n",
        "    Dense(1, activation=\"sigmoid\")  # Output layer for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adagrad(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=300, batch_size=16, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "# Predict classes\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "# Confusion matrix and classification report\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred, target_names=[\"Non-Diabetic\", \"Diabetic\"])\n",
        "\n",
        "# Print results\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(report)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Non-Diabetic\", \"Diabetic\"],\n",
        "            yticklabels=[\"Non-Diabetic\", \"Diabetic\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Save the trained model\n",
        "model.save(\"/content/diabetes_ann_model.h5\")\n",
        "print(\"Model saved successfully!\")\n",
        "\n",
        "# Load the trained model and scaler\n",
        "def load_trained_model():\n",
        "    return load_model(\"/content/diabetes_ann_model.h5\"), joblib.load(\"/content/scaler.pkl\")\n",
        "\n",
        "# Predict function\n",
        "def predict_diabetes(input_data):\n",
        "    model, scaler = load_trained_model()\n",
        "    input_array = np.array(input_data).reshape(1, -1)\n",
        "    input_scaled = scaler.transform(input_array)\n",
        "    prediction = model.predict(input_scaled)\n",
        "    return \"Diabetic\" if prediction > 0.5 else \"Non-Diabetic\"\n",
        "\n",
        "# Example input\n",
        "sample_input = [6, 148, 72, 35, 0, 33.6, 0.627, 50]  # Replace with real data\n",
        "result = predict_diabetes(sample_input)\n",
        "print(f\"Prediction: {result}\")"
      ]
    }
  ]
}